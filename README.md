# 16824_VLR_ComicGen
This repository is created for the project done for 16824 - Visual Learning and Recognition course offered at CMU (Fall 2023).
This repository contains the code for a novel approach to generating comics by employing machine learning techniques. The project focuses on transforming text prompts into visually expressive comic illustrations, utilizing stable diffusion models for coherence in visual storytelling.


Permission(s)/License Required:
Access to LlaMa-2 (https://github.com/facebookresearch/codellama)


## Table of Contents

- [Introduction](#introduction)
- [Methodology](#methodology)
- [Getting Started](#getting-started)
- [Usage](#usage)
- [Results](#results)
- [Experiments](#experiments)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)

## Introduction

Comics, with their entertaining and humorous nature, seamlessly blend text and illustrations, creating a distinct and intricate form of storytelling. This project explores the potential of machine learning techniques to produce comic illustrations based on provided text prompts.

The central objectives include:
- Developing a model capable of generating comics in a specified style from textual prompts.
- Addressing questions related to style consistency across comic panels and facilitating style changes within the comic.

## Methodology

The pipeline involves a text-to-image-to-image structure, utilizing large language models, stable diffusion models, and fine-tuning techniques. The process includes story generation, prompt generation for diffusion models, stable diffusion with fine-tuning, and a control network for style transfer.

For a detailed explanation of the methodology, refer to the Methodology section in the Report.

## Getting Started

To get started with the project, follow these steps:

1. Clone the repository:

git clone https://github.com/YashPat22/16824_VLR_ComicGen
2. Install required dependencies

3. 
